{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNIwe5N7s0e_"
   },
   "source": [
    "# Real-world Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BG63Tpg8ep_"
   },
   "source": [
    "In this project, you will apply the skills you acquired in the course to gather and wrangle real-world data with two datasets of your choice.\n",
    "\n",
    "You will retrieve and extract the data, assess the data programmatically and visually, accross elements of data quality and structure, and implement a cleaning strategy for the data. You will then store the updated data into your selected database/data store, combine the data, and answer a research question with the datasets.\n",
    "\n",
    "Throughout the process, you are expected to:\n",
    "\n",
    "1. Explain your decisions towards methods used for gathering, assessing, cleaning, storing, and answering the research question\n",
    "2. Write code comments so your code is more readable\n",
    "\n",
    "Before you start, install the some of the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kaggle==1.6.12 in /home/student/.local/lib/python3.10/site-packages (1.6.12)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle==1.6.12) (4.65.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/student/.local/lib/python3.10/site-packages (from kaggle==1.6.12) (2024.7.4)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle==1.6.12) (6.1.0)\n",
      "Requirement already satisfied: python-slugify in /home/student/.local/lib/python3.10/site-packages (from kaggle==1.6.12) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle==1.6.12) (1.26.15)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle==1.6.12) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle==1.6.12) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle==1.6.12) (2.29.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle==1.6.12) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/student/.local/lib/python3.10/site-packages (from python-slugify->kaggle==1.6.12) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle==1.6.12) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle==1.6.12) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install kaggle==1.6.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ucimlrepo\n",
      "  Using cached ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
      "Collecting pandas>=1.0.0\n",
      "  Using cached pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Collecting certifi>=2020.12.5\n",
      "  Using cached certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
      "Collecting python-dateutil>=2.8.2\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Collecting numpy>=1.22.4\n",
      "  Using cached numpy-2.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Collecting six>=1.5\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pytz, tzdata, six, numpy, certifi, python-dateutil, pandas, ucimlrepo\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scipy 1.11.2 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed certifi-2024.7.4 numpy-2.1.0 pandas-2.2.2 python-dateutil-2.9.0.post0 pytz-2024.1 six-1.16.0 tzdata-2024.1 ucimlrepo-0.0.7\n",
      "\u001b[33mWARNING: Target directory /workspace/pytz-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/pandas already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/tzdata-2024.1.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/ucimlrepo already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/numpy already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/pytz already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/numpy-2.1.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/pandas-2.2.2.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/__pycache__ already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/python_dateutil-2.9.0.post0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/ucimlrepo-0.0.7.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/six.py already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/certifi-2024.7.4.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/numpy.libs already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/certifi already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/six-1.16.0.dist-info already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/dateutil already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/tzdata already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Target directory /workspace/bin already exists. Specify --upgrade to force replacement.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --target=/workspace ucimlrepo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Restart the kernel to use updated package(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDYDkH-Zs7Nn"
   },
   "source": [
    "## 1. Gather data\n",
    "\n",
    "In this section, you will extract data using two different data gathering methods and combine the data. Use at least two different types of data-gathering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbN7z7rcuqpO"
   },
   "source": [
    "### **1.1.** Problem Statement\n",
    "In 2-4 sentences, explain the kind of problem you want to look at and the datasets you will be wrangling for this project.\n",
    "\n",
    "I want to combine the adult and suicide datasets so I can see in more detail whether we can find interesting insights. The particular insight I'm curious about is whether there are different projected suicide rates by career. You often hear that lawyers and accountants have it tough from a mental health perspective. I want to gain a better insight into this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gi6swhjSYqu2"
   },
   "source": [
    "Finding the right datasets can be time-consuming. Here we provide you with a list of websites to start with. But we encourage you to explore more websites and find the data that interests you.\n",
    "\n",
    "* Google Dataset Search https://datasetsearch.research.google.com/\n",
    "* The U.S. Governmentâ€™s open data https://data.gov/\n",
    "* UCI Machine Learning Repository https://archive.ics.uci.edu/ml/index.php\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AQfBAdUypMm"
   },
   "source": [
    "### **1.2.** Gather at least two datasets using two different data gathering methods\n",
    "\n",
    "List of data gathering methods:\n",
    "\n",
    "- Download data manually\n",
    "- Programmatically downloading files\n",
    "- Gather data by accessing APIs\n",
    "- Gather and extract data from HTML files using BeautifulSoup\n",
    "- Extract data from a SQL database\n",
    "\n",
    "Each dataset must have at least two variables, and have greater than 500 data samples within each dataset.\n",
    "\n",
    "For each dataset, briefly describe why you picked the dataset and the gathering method (2-3 full sentences), including the names and significance of the variables in the dataset. Show your work (e.g., if using an API to download the data, please include a snippet of your code). \n",
    "\n",
    "Load the dataset programmtically into this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e6gS0wL1KTu"
   },
   "source": [
    "#### *UCI Adult*\n",
    "\n",
    "Type: Download Data Manually\n",
    "\n",
    "Method: We downloaded a CSV file and names, and used pandas to load it into a dataframe.\n",
    "\n",
    "Dataset variables:\n",
    "age, workclass, fnlwgt, education, education-num, marital-status, occupation,relationship, race, sex, capital-gain, capital-loss, hours-per-week, native-country, income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Su8E0uLuYkHU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#FILL IN 1st data gathering and loading method\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# URLs of the dataset files\n",
    "data_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "names_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names'\n",
    "\n",
    "# Column names (you can find these in the adult.names file or the dataset description)\n",
    "column_names = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', \n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', \n",
    "    'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "df1 = pd.read_csv(data_url, names=column_names, sep=',\\s', engine='python')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df1.head())\n",
    "print(df1.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoUjq1tPzz7P"
   },
   "source": [
    "#### Dataset 2\n",
    "\n",
    "Type: *Requests Method programmatic\n",
    "\n",
    "Method: Requests Method\n",
    "\n",
    "Dataset variables:\n",
    "\n",
    "*INDICATOR', 'UNIT', 'UNIT_NUM', 'STUB_NAME', 'STUB_NAME_NUM',\n",
    "       'STUB_LABEL', 'STUB_LABEL_NUM', 'YEAR', 'YEAR_NUM', 'AGE', 'AGE_NUM',\n",
    "       'ESTIMATE', 'FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6zT0QxRyYmm7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully loaded into a DataFrame.\n",
      "                 INDICATOR                                               UNIT  \\\n",
      "0  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "1  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "2  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "3  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "4  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "\n",
      "   UNIT_NUM STUB_NAME  STUB_NAME_NUM   STUB_LABEL  STUB_LABEL_NUM  YEAR  \\\n",
      "0         1     Total              0  All persons             0.0  1950   \n",
      "1         1     Total              0  All persons             0.0  1960   \n",
      "2         1     Total              0  All persons             0.0  1970   \n",
      "3         1     Total              0  All persons             0.0  1980   \n",
      "4         1     Total              0  All persons             0.0  1981   \n",
      "\n",
      "   YEAR_NUM       AGE  AGE_NUM  ESTIMATE FLAG  \n",
      "0         1  All ages      0.0      13.2  NaN  \n",
      "1         2  All ages      0.0      12.5  NaN  \n",
      "2         3  All ages      0.0      13.1  NaN  \n",
      "3         4  All ages      0.0      12.2  NaN  \n",
      "4         5  All ages      0.0      12.3  NaN  \n",
      "Index(['INDICATOR', 'UNIT', 'UNIT_NUM', 'STUB_NAME', 'STUB_NAME_NUM',\n",
      "       'STUB_LABEL', 'STUB_LABEL_NUM', 'YEAR', 'YEAR_NUM', 'AGE', 'AGE_NUM',\n",
      "       'ESTIMATE', 'FLAG'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#FILL IN REQUESTS Method\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "url = 'https://data.cdc.gov/resource/9j2v-jamp.json?$limit=50000'\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON data directly into a pandas DataFrame\n",
    "    df2 = pd.read_json(url)\n",
    "    print('Dataset successfully loaded into a DataFrame.')\n",
    "else:\n",
    "    print(f'Failed to retrieve the dataset. Status code: {response.status_code}')\n",
    "\n",
    "df2.columns = df2.columns.str.upper()\n",
    "\n",
    "# Display the first few rows of the second dataframe\n",
    "print(df2.head())\n",
    "\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional data storing step: You may save your raw dataset files to the local data store before moving to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: store the raw data in your local data store\n",
    "\n",
    "df1.to_csv('nonclean1.csv', index=False)\n",
    "df2.to_csv('nonclean2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwSWIVmotLgV"
   },
   "source": [
    "## 2. Assess data - I did a lot to clean up this data. I'm going to break it down into what I did, the issue, and whether it was tidiness or cleanness related in each step. \n",
    "\n",
    "Assess the data according to data quality and tidiness metrics using the report below.\n",
    "\n",
    "List **two** data quality issues and **two** tidiness issues. Assess each data issue visually **and** programmatically, then briefly describe the issue you find.  **Make sure you include justifications for the methods you use for the assessment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adaK2iPNzVu4"
   },
   "source": [
    "### Quality Issues: Suicide Dataset Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "SpW59kh-zl8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 INDICATOR                                               UNIT  \\\n",
      "0  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "1  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "2  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "3  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "4  Death rates for suicide  Deaths per 100,000 resident population, age-ad...   \n",
      "\n",
      "   UNIT_NUM STUB_NAME  STUB_NAME_NUM   STUB_LABEL  STUB_LABEL_NUM  YEAR  \\\n",
      "0         1     Total              0  All persons             0.0  1950   \n",
      "1         1     Total              0  All persons             0.0  1960   \n",
      "2         1     Total              0  All persons             0.0  1970   \n",
      "3         1     Total              0  All persons             0.0  1980   \n",
      "4         1     Total              0  All persons             0.0  1981   \n",
      "\n",
      "   YEAR_NUM       AGE  AGE_NUM  ESTIMATE FLAG  \n",
      "0         1  All ages      0.0      13.2  NaN  \n",
      "1         2  All ages      0.0      12.5  NaN  \n",
      "2         3  All ages      0.0      13.1  NaN  \n",
      "3         4  All ages      0.0      12.2  NaN  \n",
      "4         5  All ages      0.0      12.3  NaN  \n",
      "Index(['INDICATOR', 'UNIT', 'UNIT_NUM', 'STUB_NAME', 'STUB_NAME_NUM',\n",
      "       'STUB_LABEL', 'STUB_LABEL_NUM', 'YEAR', 'YEAR_NUM', 'AGE', 'AGE_NUM',\n",
      "       'ESTIMATE', 'FLAG'],\n",
      "      dtype='object')\n",
      "          UNIT_NUM  STUB_NAME_NUM  STUB_LABEL_NUM         YEAR     YEAR_NUM  \\\n",
      "count  6390.000000    6390.000000     6390.000000  6390.000000  6390.000000   \n",
      "mean      1.872926       4.621909        4.686775  1997.525822    22.692019   \n",
      "std       0.333081       2.031777        1.829624    14.937451    12.286033   \n",
      "min       1.000000       0.000000        0.000000  1950.000000     1.000000   \n",
      "25%       2.000000       3.000000        3.230000  1988.000000    12.000000   \n",
      "50%       2.000000       5.000000        5.125100  1999.000000    23.000000   \n",
      "75%       2.000000       6.000000        6.153000  2009.000000    33.000000   \n",
      "max       2.000000      11.000000        7.235000  2018.000000    42.000000   \n",
      "\n",
      "           AGE_NUM     ESTIMATE  \n",
      "count  6390.000000  5484.000000  \n",
      "mean      2.712207    13.709810  \n",
      "std       1.932280    11.531805  \n",
      "min       0.000000     0.300000  \n",
      "25%       0.000000     5.000000  \n",
      "50%       3.000000    10.500000  \n",
      "75%       4.100000    19.500000  \n",
      "max       6.000000    74.800000  \n"
     ]
    }
   ],
   "source": [
    "# Visual viewing\n",
    "print(df2.head())\n",
    "\n",
    "# I also went into Excel and looked at the data and saw a bunch of things I didn't like\n",
    "\n",
    "# Programmatic \n",
    "print(df2.columns)\n",
    "print(df2.describe())\n",
    "\n",
    "\n",
    "# Observations: This data looks terrible and is really hard to use in this form. \n",
    "\n",
    "# Here are some of the problems with it. \n",
    "\n",
    "# For DF2\n",
    "\n",
    "# Data Quality Issue 1: Not enough data for some columns I'm trying to match on. Solution: Drop rows that don't have the data I'm looking for\n",
    "\n",
    "# Data Quality Issue 2: Several of the entries lack the Estimate column, I want to only look at entries with values.\n",
    "\n",
    "# Tidiness Issue 1: In it's current form the data I want to access is comma delimited when it should be its own separate columns to be easier to sort\n",
    "\n",
    "# Tidiness Issue 2: Too many other columns are in the way, and entries which will not be available to merge (non-1994 data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-qfcocStzsKg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      GENDER        RACE           AGE_RANGE  ESTIMATE\n",
      "5304    Male       White         15-24 years      24.6\n",
      "5345    Male       White         25-44 years      26.7\n",
      "5387    Male       White         45-64 years      24.2\n",
      "5429    Male       White   65 years and over      39.5\n",
      "5639    Male   All races         15-24 years      16.8\n",
      "5681    Male   All races         25-44 years      16.0\n",
      "5723    Male   All races         45-64 years      13.6\n",
      "5765    Male   All races   65 years and over      18.6\n",
      "5807  Female       White         15-24 years       3.9\n",
      "5849  Female       White         25-44 years       6.8\n",
      "5891  Female       White         45-64 years       7.3\n",
      "5933  Female       White   65 years and over       5.9\n",
      "6143  Female   All races         15-24 years       2.6\n",
      "6185  Female   All races         25-44 years       2.5\n",
      "6227  Female   All races         45-64 years       2.2\n",
      "6269  Female   All races   65 years and over       2.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72/1562175589.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2adj[['GENDER', 'ETHNICITY', 'RACE', 'AGE_RANGE']] = split_columns\n",
      "/tmp/ipykernel_72/1562175589.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2adj[['GENDER', 'ETHNICITY', 'RACE', 'AGE_RANGE']] = split_columns\n",
      "/tmp/ipykernel_72/1562175589.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2adj[['GENDER', 'ETHNICITY', 'RACE', 'AGE_RANGE']] = split_columns\n",
      "/tmp/ipykernel_72/1562175589.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2adj[['GENDER', 'ETHNICITY', 'RACE', 'AGE_RANGE']] = split_columns\n"
     ]
    }
   ],
   "source": [
    "# First, I'd like to only look at data that I can cross-apply to the adult data set. \n",
    "# I also wanted to look at only STUB_LABELS that had 3 columns so that I could more generally match to adult data set.\n",
    "\n",
    "# Data Quality Issue 1: Not enough data for some columns I'm trying to match on. Solution: Drop rows that don't have the data I'm looking for\n",
    "# Step 1: Cleaning - Filter down to appropriate year and STUB_LABEL containing exactly three colons\n",
    "\n",
    "# Step 1: Cleaning - Filter down to appropriate year and STUB_LABEL containing exactly three colons\n",
    "df2adj = df2[(df2['YEAR'] == 1994) & (df2['STUB_LABEL'].str.count(':') == 3)]\n",
    "\n",
    "\n",
    "# Step 2: Tidying - Split 'STUB_LABEL' into 'GENDER', 'ETHNICITY', 'RACE', and 'AGE_RANGE'\n",
    "split_columns = df2adj['STUB_LABEL'].str.split(':', expand=True)\n",
    "\n",
    "\n",
    "# Ensure that there are exactly four columns after the split before assigning\n",
    "if split_columns.shape[1] == 4:\n",
    "    df2adj[['GENDER', 'ETHNICITY', 'RACE', 'AGE_RANGE']] = split_columns\n",
    "else:\n",
    "    print(f\"Warning: The split did not result in exactly 4 columns. Found {split_columns.shape[1]} columns.\")\n",
    "\n",
    "# Step 3: Tidying - Keep only the columns 'GENDER', 'RACE', 'AGE_RANGE', and 'ESTIMATE'\n",
    "df2adj = df2adj[['GENDER', 'RACE', 'AGE_RANGE', 'ESTIMATE']]\n",
    "\n",
    "# Step 4: Cleaning - Drop rows with NaN values in the 'ESTIMATE' column\n",
    "df2adj = df2adj.dropna(subset=['ESTIMATE'])\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df2adj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: I wrote out each issue for this throughout the coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Be77N4I1AmE"
   },
   "source": [
    "### Quality Issues: Adult DataSet Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iMhHyiyLM2I3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         State-gov   77516  Bachelors             13   \n",
      "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
      "2   38           Private  215646    HS-grad              9   \n",
      "3   53           Private  234721       11th              7   \n",
      "4   28           Private  338409  Bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
      "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
      "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
      "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
      "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \n",
      "0          2174             0              40  United-States  <=50K  \n",
      "1             0             0              13  United-States  <=50K  \n",
      "2             0             0              40  United-States  <=50K  \n",
      "3             0             0              40  United-States  <=50K  \n",
      "4             0             0              40           Cuba  <=50K  \n",
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'income'],\n",
      "      dtype='object')\n",
      "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "count  32561.000000  3.256100e+04   32561.000000  32561.000000  32561.000000   \n",
      "mean      38.581647  1.897784e+05      10.080679   1077.648844     87.303830   \n",
      "std       13.640433  1.055500e+05       2.572720   7385.292085    402.960219   \n",
      "min       17.000000  1.228500e+04       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.178270e+05       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.783560e+05      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  2.370510e+05      12.000000      0.000000      0.000000   \n",
      "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
      "\n",
      "       hours-per-week  \n",
      "count    32561.000000  \n",
      "mean        40.437456  \n",
      "std         12.347429  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72/3255746919.py:23: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df1adj = df1adj.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
      "/tmp/ipykernel_72/3255746919.py:25: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df1adj = df1adj.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age         workclass  fnlwgt  education  education-num  \\\n",
      "0   39         state-gov   77516  bachelors             13   \n",
      "1   50  self-emp-not-inc   83311  bachelors             13   \n",
      "2   38           private  215646    hs-grad              9   \n",
      "3   53           private  234721       11th              7   \n",
      "4   28           private  338409  bachelors             13   \n",
      "\n",
      "       marital-status         occupation   relationship   race     sex  \\\n",
      "0       never-married       adm-clerical  not-in-family  white    male   \n",
      "1  married-civ-spouse    exec-managerial        husband  white    male   \n",
      "2            divorced  handlers-cleaners  not-in-family  white    male   \n",
      "3  married-civ-spouse  handlers-cleaners        husband  black    male   \n",
      "4  married-civ-spouse     prof-specialty           wife  black  female   \n",
      "\n",
      "   capital-gain  capital-loss  hours-per-week native-country income  \\\n",
      "0          2174             0              40  united-states  <=50k   \n",
      "1             0             0              13  united-states  <=50k   \n",
      "2             0             0              40  united-states  <=50k   \n",
      "3             0             0              40  united-states  <=50k   \n",
      "4             0             0              40           cuba  <=50k   \n",
      "\n",
      "  age_category  \n",
      "0        25-44  \n",
      "1        45-64  \n",
      "2        25-44  \n",
      "3        45-64  \n",
      "4        25-44  \n",
      "   age age_category\n",
      "0   39        25-44\n",
      "1   50        45-64\n",
      "2   38        25-44\n",
      "3   53        45-64\n",
      "4   28        25-44\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the dataframe visually\n",
    "\n",
    "print(df1.head())\n",
    "\n",
    "print(df1.columns)\n",
    "\n",
    "# Inspecting the dataframe programmatically\n",
    "\n",
    "print(df1.describe())\n",
    "\n",
    "# For DF1, Quality Issue 1: Some missing values exist.\n",
    "\n",
    "df1adj = df1\n",
    "\n",
    "#Step 1 - Cleaning: Let's fill them in as unknown\n",
    "df1adj.replace('?', pd.NA, inplace=True)\n",
    "df1adj.fillna('Unknown', inplace=True)\n",
    "\n",
    "# #For Df1, Quality Issue 2: There are some spaces between delimiters, potentially leading to issues.\n",
    "\n",
    "#Step 2 Cleaning - There are some spaces between the delimiters, potentially leading to data analysis problems in adult dataset\n",
    "\n",
    "df1adj = df1adj.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "df1adj = df1adj.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "# For Df1, Tidiness Issue 1: Discrete ages is more specific than the suicide dataset. This will lead to a data tidiness issue\n",
    "\n",
    "#Let's also make sure that we can tidy this data to combine with the suicide dataset. In this step, we'll break the ages into bins.\n",
    "\n",
    "age_bins = [15, 24, 44, 64, float('inf')]\n",
    "age_labels = ['15-24', '25-44', '45-64', '65+']\n",
    "df1adj['age_category'] = pd.cut(df1adj['age'], bins=age_bins, labels=age_labels, right=True)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df1adj.head())\n",
    "print(df1adj[['age', 'age_category']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bnviRCUI-bb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  age_category         occupation   race     sex\n",
      "0        25-44       adm-clerical  white    male\n",
      "1        45-64    exec-managerial  white    male\n",
      "2        25-44  handlers-cleaners  white    male\n",
      "3        45-64  handlers-cleaners  black    male\n",
      "4        25-44     prof-specialty  black  female\n",
      "Index(['age_category', 'occupation', 'race', 'sex'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# For Df1, Tidiness Issue 2: This data is too hard to manage with all the extra columns. \n",
    "\n",
    "#Let's keep only a few more columns to really focus\n",
    "\n",
    "columns_to_keep = [\n",
    "    'age_category', 'occupation', 'race', 'sex'\n",
    "]\n",
    "df1adj = df1adj.loc[:, columns_to_keep]\n",
    "\n",
    "# Confirming data is easy to read\n",
    "print(df1adj.head())\n",
    "print(df1adj.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: Now the data looks a lot easier to work with/wrangle because it's more manageable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXhGiYyiwwKN"
   },
   "source": [
    "### Now we gotta make the data able to be merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fleC5rORI0Xl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  age_category         occupation   race     sex\n",
      "0        25-44       adm-clerical  white    male\n",
      "1        45-64    exec-managerial  white    male\n",
      "2        25-44  handlers-cleaners  white    male\n",
      "3        45-64  handlers-cleaners  black    male\n",
      "4        25-44     prof-specialty  black  female\n",
      "     GENDER        RACE           AGE_RANGE  ESTIMATE\n",
      "5304   Male       White         15-24 years      24.6\n",
      "5345   Male       White         25-44 years      26.7\n",
      "5387   Male       White         45-64 years      24.2\n",
      "5429   Male       White   65 years and over      39.5\n",
      "5639   Male   All races         15-24 years      16.8\n"
     ]
    }
   ],
   "source": [
    "# We'll do a direct comparison of heads\n",
    "\n",
    "print(df1adj.head())\n",
    "print(df2adj.head())\n",
    "\n",
    "# Notice similar concepts but have different column headings, values. We'll have to convert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BTuQw7Rbsio4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  age_category         occupation   race     sex\n",
      "0        25-44       adm-clerical  white    male\n",
      "1        45-64    exec-managerial  white    male\n",
      "2        25-44  handlers-cleaners  white    male\n",
      "3        45-64  handlers-cleaners  black    male\n",
      "4        25-44     prof-specialty  black  female\n",
      "     GENDER        RACE           AGE_RANGE  ESTIMATE\n",
      "5304   Male       White         15-24 years      24.6\n",
      "5345   Male       White         25-44 years      26.7\n",
      "5387   Male       White         45-64 years      24.2\n",
      "5429   Male       White   65 years and over      39.5\n",
      "5639   Male   All races         15-24 years      16.8\n",
      "  AGE_RANGE         OCCUPATION   RACE  GENDER\n",
      "0     25-44       adm-clerical  white    male\n",
      "1     45-64    exec-managerial  white    male\n",
      "2     25-44  handlers-cleaners  white    male\n",
      "3     45-64  handlers-cleaners  black    male\n",
      "4     25-44     prof-specialty  black  female\n",
      "     GENDER        RACE AGE_RANGE  ESTIMATE\n",
      "5304   male       white     15-24      24.6\n",
      "5345   male       white     25-44      26.7\n",
      "5387   male       white     45-64      24.2\n",
      "5429   male       white       65+      39.5\n",
      "5639   male   all races     15-24      16.8\n",
      "AGE_RANGE     category\n",
      "OCCUPATION      object\n",
      "RACE            object\n",
      "GENDER          object\n",
      "dtype: object\n",
      "GENDER        object\n",
      "RACE          object\n",
      "AGE_RANGE     object\n",
      "ESTIMATE     float64\n",
      "dtype: object\n",
      "AGE_RANGE     object\n",
      "OCCUPATION    object\n",
      "RACE          object\n",
      "GENDER        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df1adj.head())\n",
    "print(df2adj.head())\n",
    "\n",
    "#Tidiness Issue 3 - Columns are not a 1-1 match in terms of name\n",
    "# Tidying, let's make sure the columns are a 1-1 match in terms of names. Decided to capitalize occupation so it would look nice.\n",
    "\n",
    "df1adj = df1adj.rename(columns={\n",
    "    'sex': 'GENDER',\n",
    "    'age_category': 'AGE_RANGE',\n",
    "    'race': 'RACE',\n",
    "    'occupation': 'OCCUPATION'\n",
    "})\n",
    "print(df1adj.head())\n",
    "\n",
    "# Tidiness Issue 4 - Values in GENDER, and RACE are mismatched across dataframes\n",
    "# Tidying -Convert values in the 'GENDER' column to lowercase\n",
    "df2adj['GENDER'] = df2adj['GENDER'].str.lower()\n",
    "\n",
    "# Tidying Convert values in the 'RACE' column to lowercase\n",
    "df2adj['RACE'] = df2adj['RACE'].str.lower()\n",
    "\n",
    "#Tidiness Issue 5 - Slightly different naming conventions across dataframes\n",
    "# Tidying data so that we're using the same naming conventions to be able to merge\n",
    "\n",
    "df2adj['AGE_RANGE'] = df2adj['AGE_RANGE'].str.strip()\n",
    "\n",
    "age_range_replacements = {\n",
    "    '15-24 years': '15-24',\n",
    "    '25-44 years': '25-44',\n",
    "    '45-64 years': '45-64',\n",
    "    '65 years and over': '65+'\n",
    "}\n",
    "\n",
    "# Now we're applying the replacements to the 'AGE_RANGE' column\n",
    "df2adj['AGE_RANGE'] = df2adj['AGE_RANGE'].replace(age_range_replacements)\n",
    "\n",
    "# Checking to see if it worked\n",
    "\n",
    "print(df2adj.head())\n",
    "\n",
    "# Data quality issue 3: I tried merging in a different cell at this point. Noticed the dataframe was empty, had to troubleshoot. Checking datatypes to see if they match up.\n",
    "\n",
    "print(df1adj.dtypes)\n",
    "print(df2adj.dtypes)\n",
    "\n",
    "# Tidying data so that datatypes match\n",
    "\n",
    "df1adj['AGE_RANGE'] = df1adj['AGE_RANGE'].astype(object)\n",
    "print(df1adj.dtypes)\n",
    "\n",
    "# I was still running into issues having entries in my dataframe. At this point, I wanted to make sure there were no extraneous spaces.\n",
    "\n",
    "# Data quality issue 4: Some columns might have unnecessary spaces preventing matching.\n",
    "\n",
    "#We're cleaning the data so it has no spaces\n",
    "\n",
    "df1adj['GENDER'] = df1adj['GENDER'].str.strip()\n",
    "df1adj['RACE'] = df1adj['RACE'].str.strip()\n",
    "df1adj['AGE_RANGE'] = df1adj['AGE_RANGE'].str.strip()\n",
    "\n",
    "df2adj['GENDER'] = df2adj['GENDER'].str.strip()\n",
    "df2adj['RACE'] = df2adj['RACE'].str.strip()\n",
    "df2adj['AGE_RANGE'] = df2adj['AGE_RANGE'].str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got data that should work. (It should work because I've been trying to merge unsuccessfully for a while at this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ffMoRGSwzYj"
   },
   "source": [
    "### Creating the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XUpeoqokw5Qt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AGE_RANGE         OCCUPATION   RACE  GENDER  ESTIMATE\n",
      "0      25-44       adm-clerical  white    male      26.7\n",
      "1      45-64    exec-managerial  white    male      24.2\n",
      "2      25-44  handlers-cleaners  white    male      26.7\n",
      "3      25-44    exec-managerial  white  female       6.8\n",
      "4      45-64    exec-managerial  white    male      24.2\n",
      "5      25-44     prof-specialty  white  female       6.8\n",
      "6      25-44    exec-managerial  white    male      26.7\n",
      "7      15-24       adm-clerical  white  female       3.9\n",
      "8      25-44    farming-fishing  white    male      26.7\n",
      "9      25-44  machine-op-inspct  white    male      26.7\n",
      "10     25-44              sales  white    male      26.7\n",
      "11     25-44    exec-managerial  white  female       6.8\n",
      "12     25-44     prof-specialty  white    male      26.7\n",
      "13     25-44   transport-moving  white    male      26.7\n",
      "14     45-64       tech-support  white  female       7.3\n",
      "15     45-64       tech-support  white    male      24.2\n",
      "16     15-24       craft-repair  white    male      24.6\n",
      "17     25-44    exec-managerial  white    male      26.7\n",
      "18     45-64       craft-repair  white    male      24.2\n",
      "19     15-24    protective-serv  white    male      24.6\n"
     ]
    }
   ],
   "source": [
    "# Now we're merging the datasets to verify that we're having entries that work\n",
    "\n",
    "merged_df = pd.merge(df1adj, df2adj[['GENDER', 'RACE', 'AGE_RANGE', 'ESTIMATE']], \n",
    "                     on=['GENDER', 'RACE', 'AGE_RANGE'], \n",
    "                     how='inner')\n",
    "print(merged_df.head(20))\n",
    "\n",
    "# It looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8JK4DoXxtFA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't that look great?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6gmLnBttpCh"
   },
   "source": [
    "## 3. Clean data\n",
    "Clean the data to solve the 4 issues corresponding to data quality and tidiness found in the assessing step. **Make sure you include justifications for your cleaning decisions.**\n",
    "\n",
    "After the cleaning for each issue, please use **either** the visually or programatical method to validate the cleaning was succesful.\n",
    "\n",
    "At this stage, you are also expected to remove variables that are unnecessary for your analysis and combine your datasets. Depending on your datasets, you may choose to perform variable combination and elimination before or after the cleaning stage. Your dataset must have **at least** 4 variables after combining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGE_RANGE      object\n",
      "OCCUPATION     object\n",
      "RACE           object\n",
      "GENDER         object\n",
      "ESTIMATE      float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmFhN52Yyn3l"
   },
   "source": [
    "### **Quality Issue 1: Completed Above**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9UejDWrNMW4a"
   },
   "outputs": [],
   "source": [
    "# You may note that I've done this in detail above\n",
    "\n",
    "\n",
    "#For ease of grading:\n",
    "\n",
    "# For DF1, Quality Issue 1: Some missing values exist.\n",
    "#For Df1, Quality Issue 2: There are some spaces between delimiters, potentially leading to issues.\n",
    "# For Df1, Tidiness Issue 2: This data is too hard to manage with all the extra columns. \n",
    "#For Df1, Tidiness Issue 3 - Columns are not a 1-1 match in terms of name\n",
    "#For Df1, Tidiness Issue 4 - Values in GENDER, and RACE are mismatched across dataframes\n",
    "#Tidiness Issue 5 - Slightly different naming conventions across dataframes\n",
    "\n",
    "# Data quality issue 3: I tried merging in a different cell at this point. Noticed the dataframe was empty, had to troubleshoot. Checking datatypes to see if they match up.\n",
    "\n",
    "# Data quality issue 4: Some columns might have unnecessary spaces preventing matching.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For DF2\n",
    "\n",
    "# Data Quality Issue 1: Not enough data for some columns I'm trying to match on. Solution: Drop rows that don't have the data I'm looking for\n",
    "\n",
    "# Data Quality Issue 2: Several of the entries lack the Estimate column, I want to only look at entries with values.\n",
    "\n",
    "# Tidiness Issue 1: In it's current form the data I want to access is comma delimited when it should be its own separate columns to be easier to sort\n",
    "\n",
    "# Tidiness Issue 2: Too many other columns are in the way, and entries which will not be available to merge (non-1994 data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oUBee-LPytkv"
   },
   "outputs": [],
   "source": [
    "# Observe the prior cleaning I've been doing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: I did a bunch of cleaning in the issues section, and noted what they were"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_DAUbJrymBL"
   },
   "source": [
    "### See above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5Yfb-Yu5MTuE"
   },
   "outputs": [],
   "source": [
    "#See above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ionB2sRaMUmY"
   },
   "outputs": [],
   "source": [
    "See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: I explain why I do what I do above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIUrrfSNyOPR"
   },
   "source": [
    "### **See above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fib0zAm333bn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhrnUGY_Nk8B"
   },
   "outputs": [],
   "source": [
    "#See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o51Bt8kwyTzk"
   },
   "source": [
    "### See above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zW8O5yx4Y9O"
   },
   "outputs": [],
   "source": [
    "#See above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6I_Sr7lxXi5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: See above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove unnecessary variables and combine datasets**\n",
    "\n",
    "Depending on the datasets, you can also peform the combination before the cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has been done in an earlier step - brought down for ease of grading\n",
    "\n",
    "#Stripping all unnecessary columns\n",
    "\n",
    "# columns_to_keep = [\n",
    "    #'age_category', 'occupation', 'race', 'sex']\n",
    "\n",
    "# df1adj = df1.loc[:, columns_to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F42urHuzttjF"
   },
   "source": [
    "## 4. Update your data store\n",
    "Update your local database/data store with the cleaned data, following best practices for storing your cleaned data:\n",
    "\n",
    "- Must maintain different instances / versions of data (raw and cleaned data)\n",
    "- Must name the dataset files informatively\n",
    "- Ensure both the raw and cleaned data is saved to your database/data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "V3uay7EJUV_L"
   },
   "outputs": [],
   "source": [
    "# df1 is essentially uncleaned whereas df1adj has been modified signficantly. The same can be said for df2 and df2adj\n",
    "\n",
    "merged_df.to_csv('merged.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGy_yddGtzhM"
   },
   "source": [
    "## 5. Answer the research question\n",
    "\n",
    "### **5.1:** Define and answer the research question \n",
    "Going back to the problem statement in step 1, use the cleaned data to answer the question you raised. Produce **at least** two visualizations using the cleaned data and explain how they help you answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjedE4s4ZkEd"
   },
   "source": [
    "*Research question:* Do Different Professions Have Different Estimated Suicide Rates per 100 K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lkw3rW9kZmOm",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: 1: cannot open 2.0: No such file\n",
      "Found existing installation: matplotlib 3.7.2\n",
      "Uninstalling matplotlib-3.7.2:\n",
      "  Would remove:\n",
      "    /opt/conda/lib/python3.10/site-packages/matplotlib-3.7.2-py3.10-nspkg.pth\n",
      "    /opt/conda/lib/python3.10/site-packages/matplotlib-3.7.2.dist-info/*\n",
      "    /opt/conda/lib/python3.10/site-packages/matplotlib/*\n",
      "    /opt/conda/lib/python3.10/site-packages/mpl_toolkits/axes_grid1/*\n",
      "    /opt/conda/lib/python3.10/site-packages/mpl_toolkits/axisartist/*\n",
      "    /opt/conda/lib/python3.10/site-packages/mpl_toolkits/mplot3d/*\n",
      "    /opt/conda/lib/python3.10/site-packages/pylab.py\n",
      "Proceed (Y/n)? "
     ]
    }
   ],
   "source": [
    "!pip install numpy<2.0\n",
    "!pip uninstall matplotlib seaborn\n",
    "!pip install matplotlib seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Calculate average estimate by occupation\n",
    "occupation_avg_estimate = merged_df.groupby('OCCUPATION')['ESTIMATE'].mean().reset_index()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=occupation_avg_estimate, x='OCCUPATION', y='ESTIMATE', palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Average Estimate by Occupation')\n",
    "plt.xlabel('Occupation')\n",
    "plt.ylabel('Average Estimate')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Yes, it appears they do. Farming/Fishing appears to be the highest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to research question:* Yes, some of the highest suicide rates include farming/fishing, transport mining, and some of the lowest include  priv-house serving and adm-clerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fdK_8ZGZm9R"
   },
   "outputs": [],
   "source": [
    "# A second visualization\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=merged_df, x='OCCUPATION', y='ESTIMATE', palette='viridis')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Distribution of Estimates by Occupation')\n",
    "plt.xlabel('Occupation')\n",
    "plt.ylabel('Estimate')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5RgvMGUZoHn"
   },
   "source": [
    "*Answer to research question:* Estimated suicide rates are different by career because different demographics occupy different careers to some extent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ezWXXZVj-TP"
   },
   "source": [
    "### **5.2:** Reflection\n",
    "In 2-4 sentences, if you had more time to complete the project, what actions would you take? For example, which data quality and structural issues would you look into further, and what research questions would you further explore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB3RBDG5kFe1"
   },
   "source": [
    "*Answer:* If I had more time to explore this data, I would try to more robustly control for race, as some of the data was low-quality. I'd also like to find more insights and controls in order to make this data more likely to be causal, one direction or another. I think if I could find actual values of suicides per 100 K by career and compare to the adult dataset, that would be an interesting research project to determine which careers do better or worse for stress, holding demographics equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
